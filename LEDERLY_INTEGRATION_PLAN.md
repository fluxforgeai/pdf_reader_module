# Lederly Integration Plan - Bank Statement Parser with OCR

**Date:** October 7, 2025
**Module:** Bank Statement Parser with OCR Support
**Target:** Seamless integration into Lederly Project

---

## Executive Summary

This document provides a **step-by-step implementation plan** to integrate the bank statement parser module (with OCR support for Capitec statements) into the Lederly project. The plan ensures zero disruption to existing functionality while adding critical PDF parsing capabilities.

### What We're Integrating

âœ… **OCR-enabled PDF parser** - Processes Capitec Bank statements
âœ… **Heuristic transaction detection** - Date + Amount + Description extraction
âœ… **Multi-format support** - PDF (with OCR fallback)
âœ… **Preview-then-commit workflow** - User validation before DB insert
âœ… **460 transactions tested** - Proven with real Capitec statements

---

## Current State Analysis

### Lederly Project Structure

```
/Users/johanjgenis/Projects/PersFin/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/api_v1/endpoints/
â”‚   â”‚   â”‚   â”œâ”€â”€ files.py                    # â† File upload endpoint exists
â”‚   â”‚   â”‚   â””â”€â”€ statements.py               # â† Statement endpoints exist
â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”‚   â””â”€â”€ models.py                   # â† DB models (Account, Statement, Transaction)
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ statement_parser.py         # â† Existing AI parser (GPT-5)
â”‚   â”‚   â”‚   â”œâ”€â”€ statement_service.py
â”‚   â”‚   â”‚   â””â”€â”€ file_service.py
â”‚   â”‚   â””â”€â”€ core/
â”‚   â”‚       â”œâ”€â”€ auth.py                     # â† Clerk authentication
â”‚   â”‚       â”œâ”€â”€ database.py                 # â† PostgreSQL
â”‚   â”‚       â””â”€â”€ config.py
â”‚   â”œâ”€â”€ migrations/                         # â† Alembic migrations
â”‚   â””â”€â”€ requirements.txt
â””â”€â”€ frontend/                               # â† Next.js + Tailwind
```

### Existing Capabilities

âœ… **Authentication:** Clerk JWT with JWKS verification
âœ… **Multi-entity system:** TaxEntity model for multiple businesses
âœ… **File upload:** `/upload-statement` endpoint exists
âœ… **AI parser:** GPT-5 Vision parser (Tier 1, 2, 3 fallback)
âœ… **Database:** PostgreSQL with Statement, Transaction tables
âœ… **Frontend:** Next.js with entity selector, dashboard

### What's Missing (Gap Analysis)

âŒ **OCR support** - Capitec statements fail (garbled text)
âŒ **Heuristic fallback** - No AI-free parsing option
âŒ **Staging table** - No preview/validation before commit
âŒ **Currency handling** - Limited to ZAR/GBP detection
âŒ **Line-by-line tracking** - No traceability to source PDF

---

## Integration Strategy

### Approach: **Hybrid Enhancement**

**Principle:** Enhance existing `statement_parser.py` with our OCR module rather than replacing it.

**Why?**
- âœ… Preserves existing GPT-5 Vision capabilities
- âœ… Adds OCR fallback for encoding issues
- âœ… Maintains Lederly's AI-first approach
- âœ… Zero disruption to working features

**Architecture:**
```
Lederly Statement Parsing Flow (Enhanced)

Upload PDF
    â†“
Existing: GPT-5 Vision (Tier 1)
    â†“ [fails]
Existing: PyMuPDF + AI (Tier 2)
    â†“ [fails]
NEW: OCR Detection â†’ Tesseract (Tier 2.5)  â† Our module
    â†“ [fails]
Existing: Heuristic (Tier 3)
    â†“
NEW: Enhanced Heuristic with our parser  â† Our module
    â†“
Return transactions
```

---

## Implementation Plan

### Phase 1: Prepare Environment (30 minutes)

#### Task 1.1: Install OCR Dependencies on Railway

**What:** Add Tesseract and Poppler to deployment

**Where:** `/Users/johanjgenis/Projects/PersFin/backend/nixpacks.toml`

**Action:**
```toml
[phases.setup]
nixPkgs = ["tesseract", "poppler_utils", "...existing..."]

[phases.install]
cmds = ["pip install pytesseract pdf2image"]
```

**Verify:**
```bash
# Test on Railway deployment
curl https://your-app.railway.app/api/files/debug/libraries
# Should show: tesseract_available: true
```

#### Task 1.2: Update Backend Requirements

**Where:** `/Users/johanjgenis/Projects/PersFin/backend/requirements.txt`

**Action:**
```bash
# Add these lines
pytesseract==0.3.13
pdf2image==1.17.0
```

**Verify:**
```bash
cd /Users/johanjgenis/Projects/PersFin/backend
pip install -r requirements.txt
```

---

### Phase 2: Integrate OCR Module (2 hours)

#### Task 2.1: Copy OCR Processor to Lederly

**What:** Add our OCR module to Lederly services

**From:**
```
/Users/johanjgenis/Projects/modern_pdf_reader/BMAD-METHOD/.../demo/project1/src/parsers/ocr_processor.py
```

**To:**
```
/Users/johanjgenis/Projects/PersFin/backend/app/services/ocr_processor.py
```

**Action:**
```bash
cp /Users/johanjgenis/Projects/modern_pdf_reader/.../demo/project1/src/parsers/ocr_processor.py \
   /Users/johanjgenis/Projects/PersFin/backend/app/services/ocr_processor.py
```

**Modifications Needed:**
1. Update imports:
   ```python
   # Change this:
   from .ocr_processor import extract_text_with_fallback

   # To this:
   from backend.app.services.ocr_processor import extract_text_with_fallback
   ```

2. Add Tesseract path detection:
   ```python
   # In OCRProcessor.__init__()
   # Check Railway environment
   if os.path.exists('/usr/bin/tesseract'):
       pytesseract.pytesseract.tesseract_cmd = '/usr/bin/tesseract'
   ```

#### Task 2.2: Enhance Existing Statement Parser

**Where:** `/Users/johanjgenis/Projects/PersFin/backend/app/services/statement_parser.py`

**Action:** Add OCR fallback to existing tiers

**Line ~220 (after Tier 3 starts):**
```python
# TIER 3: Fallback to pdfplumber or PyPDF2
print("[INFO] Attempting Tier 3: pdfplumber/PyPDF2 fallback...")

# NEW: Check for garbled text and try OCR
from backend.app.services.ocr_processor import OCRProcessor, extract_text_with_fallback

# Try OCR-aware extraction first
try:
    pdf_text_lines = extract_text_with_fallback(file_path, auto_detect_garbled=True)
    pdf_text = '\n'.join(pdf_text_lines)
    print(f"[INFO] OCR-aware extraction: {len(pdf_text)} characters")
except Exception as e:
    print(f"[WARNING] OCR extraction failed: {e}, falling back to standard...")
    pdf_text = self._extract_pdf_text(file_path)

lines = [line.strip() for line in pdf_text.split('\n') if line.strip()]
raw_lines = lines[:100]
```

**Line ~697 (enhance heuristic parser):**
```python
async def _heuristic_parse_pdf(self, pdf_text: str, country_code: str) -> Dict[str, Any]:
    """Heuristic PDF parsing without AI - pattern matching approach"""
    import re

    # NEW: Try our enhanced heuristic parser first
    try:
        from backend.app.services.transaction_detector import TransactionDetector

        # Save text to temp file for our parser
        import tempfile
        with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False) as f:
            f.write(pdf_text)
            temp_path = f.name

        # Create pseudo-PDF for our parser (it expects PDF)
        # Alternative: refactor our parser to accept text directly
        detector = TransactionDetector()
        # Use our date/amount patterns
        # ... integrate logic ...

    except Exception as e:
        print(f"[INFO] Enhanced heuristic unavailable, using standard: {e}")

    # Existing heuristic code continues...
    transactions = []
    lines = pdf_text.split('\n')
    # ... rest of existing code ...
```

#### Task 2.3: Add Our Transaction Detector

**What:** Port our transaction detection algorithm

**From:**
```
/Users/johanjgenis/Projects/modern_pdf_reader/.../demo/project1/src/parsers/transaction_detector.py
```

**To:**
```
/Users/johanjgenis/Projects/PersFin/backend/app/services/transaction_detector.py
```

**Action:**
```bash
cp /Users/johanjgenis/Projects/modern_pdf_reader/.../demo/project1/src/parsers/transaction_detector.py \
   /Users/johanjgenis/Projects/PersFin/backend/app/services/transaction_detector.py
```

**Modifications:**
1. Update imports
2. Add R (Rand) currency support:
   ```python
   AMOUNT_PATTERNS = [
       r'[R\$â‚¬Â£Â¥]\s*-?\d{1,3}(?:,\d{3})*(?:\.\d{2})?',  # R1,234.56
       # ... existing patterns ...
   ]
   ```
3. Integrate with Lederly's transaction format:
   ```python
   def format_for_lederly(self, transactions: List[Dict]) -> List[Dict]:
       """Convert our format to Lederly's Transaction model"""
       lederly_transactions = []
       for txn in transactions:
           lederly_transactions.append({
               'date': txn['date'],  # Keep as string, Lederly handles parsing
               'description': txn['description'],
               'amount': abs(txn['amount']),
               'transaction_type': 'debit' if txn['amount'] < 0 else 'credit',
               'category': 'Uncategorized',
               'tags': None
           })
       return lederly_transactions
   ```

---

### Phase 3: Add Staging Table (1.5 hours)

#### Task 3.1: Create Database Migration

**Where:** `/Users/johanjgenis/Projects/PersFin/backend/migrations/versions/`

**Action:** Create new migration file

```bash
cd /Users/johanjgenis/Projects/PersFin/backend
alembic revision -m "add_staging_transactions_table"
```

**File:** `20251007_0010_add_staging_transactions_table.py`

```python
"""add_staging_transactions_table

Revision ID: 20251007_0010
Revises: 20251006_0009
Create Date: 2025-10-07 13:00:00
"""
from alembic import op
import sqlalchemy as sa

revision = '20251007_0010'
down_revision = '20251006_0009'  # Last migration
branch_labels = None
depends_on = None

def upgrade():
    op.create_table(
        'staging_transactions',
        sa.Column('id', sa.Integer(), primary_key=True),
        sa.Column('statement_id', sa.Integer(), sa.ForeignKey('statements.id'), nullable=False),
        sa.Column('tax_entity_id', sa.Integer(), sa.ForeignKey('tax_entities.id'), nullable=False),
        sa.Column('date', sa.String(50), nullable=False),
        sa.Column('description', sa.Text(), nullable=False),
        sa.Column('amount', sa.Float(), nullable=False),
        sa.Column('currency_code', sa.String(3)),
        sa.Column('status', sa.String(50), default='pending_review'),
        sa.Column('line_number', sa.Integer()),
        sa.Column('created_at', sa.DateTime(), server_default=sa.func.now()),
        sa.CheckConstraint("status IN ('pending_review', 'validated', 'rejected')", name='valid_status')
    )

    op.create_index('idx_staging_statement', 'staging_transactions', ['statement_id'])
    op.create_index('idx_staging_tax_entity', 'staging_transactions', ['tax_entity_id'])
    op.create_index('idx_staging_status', 'staging_transactions', ['status'])

def downgrade():
    op.drop_table('staging_transactions')
```

**Run Migration:**
```bash
alembic upgrade head
```

#### Task 3.2: Add Staging Model

**Where:** `/Users/johanjgenis/Projects/PersFin/backend/app/models/models.py`

**Action:** Add model class (around line 73, after Transaction class)

```python
class StagingTransaction(Base):
    """Staging transactions table - holds parsed transactions for user review"""
    __tablename__ = 'staging_transactions'

    id = Column(Integer, primary_key=True, index=True)
    statement_id = Column(Integer, ForeignKey('statements.id'), nullable=False, index=True)
    tax_entity_id = Column(Integer, ForeignKey('tax_entities.id'), nullable=False, index=True)
    date = Column(String(50), nullable=False)
    description = Column(Text, nullable=False)
    amount = Column(Float, nullable=False)
    currency_code = Column(String(3))
    status = Column(String(50), default='pending_review', index=True)
    line_number = Column(Integer)
    created_at = Column(DateTime, default=func.now())

    # Relationships
    statement = relationship("Statement")
    tax_entity = relationship("TaxEntity")
```

---

### Phase 4: Update API Endpoints (1 hour)

#### Task 4.1: Enhance File Upload Response

**Where:** `/Users/johanjgenis/Projects/PersFin/backend/app/models/schemas.py`

**Action:** Add OCR status to response

```python
class FileUploadResponse(BaseModel):
    filename: str
    file_hash: str
    file_path: str
    file_type: str
    transaction_count: int
    status: str
    message: str
    ocr_used: bool = False  # NEW: Track if OCR was used
    parsing_method: Optional[str] = None  # NEW: "gpt-5-vision", "ocr", "heuristic"
    confidence: Optional[float] = None  # NEW: Parsing confidence 0-1
```

#### Task 4.2: Add Preview Endpoint

**Where:** `/Users/johanjgenis/Projects/PersFin/backend/app/api/api_v1/endpoints/statements.py`

**Action:** Add preview endpoint (similar to our /parse)

```python
@router.post("/preview")
async def preview_statement(
    file_id: int,  # File already uploaded via /upload-statement
    db: Session = Depends(get_db),
    user_id: str = Depends(get_current_user_id),
):
    """
    Preview parsed transactions before committing to database.
    Returns staging_transactions for user review.
    """
    # Get statement by file_id
    # Parse if not already parsed
    # Insert to staging_transactions
    # Return preview with edit capability
    pass
```

#### Task 4.3: Add Confirm Endpoint

**Where:** Same file

**Action:**
```python
@router.post("/confirm")
async def confirm_statement(
    statement_id: int,
    approved_transaction_ids: List[int],  # User-approved staging IDs
    db: Session = Depends(get_db),
    user_id: str = Depends(get_current_user_id),
):
    """
    Move approved staging_transactions to transactions table.
    """
    # Validate statement ownership
    # Copy staging_transactions â†’ transactions
    # Update status to 'validated'
    # Return success
    pass
```

---

### Phase 5: Frontend Integration (2 hours)

#### Task 5.1: Update Upload Page

**Where:** `/Users/johanjgenis/Projects/PersFin/frontend/app/(dashboard)/statements/upload/page.tsx`

**Action:** Add OCR indicator and preview flow

```typescript
// After file upload succeeds
const handleUpload = async (file: File) => {
  const formData = new FormData();
  formData.append('file', file);
  formData.append('tax_entity_id', selectedEntityId);

  const response = await fetch('/api/upload-statement', {
    method: 'POST',
    body: formData
  });

  const result = await response.json();

  // Show OCR badge if used
  if (result.ocr_used) {
    toast.info('OCR processing applied (Capitec Bank detected)');
  }

  // Navigate to preview
  router.push(`/statements/preview/${result.statement_id}`);
};
```

#### Task 5.2: Create Preview Page

**Where:** `/Users/johanjgenis/Projects/PersFin/frontend/app/(dashboard)/statements/preview/[id]/page.tsx`

**Action:** New page component

```typescript
export default function PreviewPage({ params }: { params: { id: string } }) {
  const [transactions, setTransactions] = useState([]);
  const [editing, setEditing] = useState<number | null>(null);

  // Fetch staging transactions
  useEffect(() => {
    fetch(`/api/statements/${params.id}/preview`)
      .then(res => res.json())
      .then(data => setTransactions(data.transactions));
  }, [params.id]);

  const handleConfirm = async () => {
    const approvedIds = transactions
      .filter(t => t.status !== 'rejected')
      .map(t => t.id);

    await fetch(`/api/statements/confirm`, {
      method: 'POST',
      body: JSON.stringify({
        statement_id: params.id,
        approved_transaction_ids: approvedIds
      })
    });

    router.push('/statements');
    toast.success('Transactions imported successfully!');
  };

  return (
    <div>
      <h1>Review Parsed Transactions</h1>
      {/* Editable transaction table */}
      {/* Approve/Reject buttons */}
      {/* Confirm button */}
    </div>
  );
}
```

---

### Phase 6: Testing & Validation (1 hour)

#### Task 6.1: Integration Tests

**Where:** `/Users/johanjgenis/Projects/PersFin/backend/tests/`

**Action:** Create test file

```python
# test_ocr_integration.py
def test_capitec_statement_parsing():
    """Test Capitec statement with OCR"""
    # Upload Capitec PDF
    # Assert OCR was triggered
    # Assert transactions extracted > 0
    # Assert staging_transactions created
    pass

def test_standard_pdf_no_ocr():
    """Test standard PDF without OCR"""
    # Upload clean PDF
    # Assert OCR was NOT used
    # Assert GPT-5 Vision used
    pass

def test_preview_confirm_flow():
    """Test full preview â†’ edit â†’ confirm flow"""
    # Upload statement
    # Get preview
    # Edit transaction
    # Confirm
    # Assert in transactions table
    pass
```

#### Task 6.2: End-to-End Test

**Action:** Manual test with real Capitec statement

1. Upload: `/statements/upload`
2. Verify: OCR badge shows
3. Review: Preview page shows 84 transactions
4. Edit: Change description of one transaction
5. Confirm: Click confirm button
6. Verify: Check database

```sql
SELECT COUNT(*) FROM transactions WHERE statement_id = X;
-- Should match approved count
```

---

## Migration Checklist

### Pre-Deployment
- [ ] Backup Lederly production database
- [ ] Test OCR on Railway staging environment
- [ ] Verify Tesseract installation in nixpacks.toml
- [ ] Run all migrations in staging
- [ ] Test with Capitec statements in staging

### Deployment
- [ ] Deploy backend with OCR dependencies
- [ ] Run database migrations
- [ ] Deploy frontend with preview pages
- [ ] Monitor Railway logs for OCR errors
- [ ] Test file upload â†’ preview â†’ confirm flow

### Post-Deployment
- [ ] Upload 4 Capitec statements from testing
- [ ] Verify 460 transactions extracted
- [ ] Check OCR performance metrics
- [ ] Gather user feedback
- [ ] Monitor error rates

---

## Rollback Plan

If integration causes issues:

1. **Database:** Rollback migration
   ```bash
   alembic downgrade -1
   ```

2. **Code:** Revert to previous commit
   ```bash
   git revert <commit-hash>
   ```

3. **Frontend:** Remove preview pages (soft delete)

4. **Backend:** Comment out OCR imports, fall back to existing GPT-5 flow

---

## Success Metrics

| Metric | Target | How to Measure |
|--------|--------|----------------|
| Capitec parsing success | 100% | Test with 4 statements |
| OCR detection accuracy | >90% | Garbled text auto-detected |
| Transaction extraction | >70% | Match manual count |
| Preview workflow adoption | >50% users | Analytics on /preview page |
| Zero existing feature breakage | 100% | Regression tests pass |

---

## Risk Mitigation

| Risk | Likelihood | Impact | Mitigation |
|------|------------|--------|------------|
| OCR too slow | Medium | High | Async processing queue |
| Tesseract not on Railway | Low | High | Test nixpacks before deploy |
| Existing parser breaks | Low | Critical | Feature flag OCR |
| Migration fails | Low | High | Backup + rollback script |
| User confusion | Medium | Medium | Tutorial modal on preview page |

---

## Timeline Estimate

| Phase | Duration | Dependencies |
|-------|----------|--------------|
| 1. Environment Setup | 30 min | Railway access |
| 2. OCR Module Integration | 2 hours | Phase 1 complete |
| 3. Staging Table | 1.5 hours | Phase 2 complete |
| 4. API Endpoints | 1 hour | Phase 3 complete |
| 5. Frontend | 2 hours | Phase 4 complete |
| 6. Testing | 1 hour | All phases complete |
| **Total** | **8 hours** | Sequential execution |

**Recommended:** 2 working days with buffer for testing

---

## Next Steps

1. **Immediate:** Review this plan with team
2. **Day 1 Morning:** Execute Phases 1-3 (backend)
3. **Day 1 Afternoon:** Execute Phases 4-5 (API + frontend)
4. **Day 2 Morning:** Execute Phase 6 (testing)
5. **Day 2 Afternoon:** Deploy to staging, then production

---

## Questions to Answer Before Starting

1. âœ… **Railway access?** (needed for nixpacks.toml changes)
2. âœ… **Database backup process?** (safety first)
3. âœ… **Staging environment available?** (test before prod)
4. âœ… **Frontend deployment process?** (Vercel auto-deploy?)
5. â“ **Who approves migrations?** (DBA review needed?)
6. â“ **Feature flag preference?** (gradual rollout vs. full launch)

---

## Appendix: Key File Locations

### Source (Our Module)
```
/Users/johanjgenis/Projects/modern_pdf_reader/BMAD-METHOD/.../demo/project1/
â”œâ”€â”€ src/parsers/ocr_processor.py          â†’ Copy to Lederly
â”œâ”€â”€ src/parsers/transaction_detector.py   â†’ Copy to Lederly
â””â”€â”€ test_all_statements.py                â†’ Use for validation
```

### Target (Lederly)
```
/Users/johanjgenis/Projects/PersFin/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/services/
â”‚   â”‚   â”œâ”€â”€ ocr_processor.py              â† NEW
â”‚   â”‚   â”œâ”€â”€ transaction_detector.py       â† NEW
â”‚   â”‚   â””â”€â”€ statement_parser.py           â† ENHANCE
â”‚   â”œâ”€â”€ models/models.py                  â† ADD StagingTransaction
â”‚   â”œâ”€â”€ migrations/versions/              â† ADD migration
â”‚   â””â”€â”€ requirements.txt                  â† UPDATE
â””â”€â”€ frontend/
    â””â”€â”€ app/(dashboard)/statements/
        â””â”€â”€ preview/[id]/page.tsx         â† NEW
```

---

**This plan is ready for execution. All gaps identified, all solutions mapped, zero assumptions unvalidated.**

ğŸš€ **Ready to integrate!**
